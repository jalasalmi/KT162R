---
title: "Sample selection simulations"
author: "Juho Alasalmi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

devtools::load_all()
library(MASS)
library(sampleSelection)
library(maxLik)

```

See how sampleSelection package and the self-made sartori-estimator fare in simulations. Start with a single explanatory variable. See Sartori (2003).

Create an explanatory variable by drawing N observations from a normal distribution with mean 0 and variance 0.64. 

```{r}
 
N = 1000
x <- rnorm(N, mean = 0, sd = sqrt(0.64))


```

Given the explanatory variable x, run I iterations, where in each iteration N errors are sampled and selection and outcome variables computed. 

Generate errors from bivariate standard normal distribution with covariance rho.Use the latent population regression functions to compute the selection variable ys and outcome variable yo.

```{r}

r = 0.9
Sigma <- matrix(c(1,r,r,1), ncol = 2)
I <- 1000

heckit_coefs <- numeric(I)
sartori_coefs <- numeric(I)
probit_coefs <- numeric(I)

for(i in 1:I) {

  errors <- MASS::mvrnorm(N, mu = c(0,0), Sigma = Sigma)

  ys <- 1.25 * x + errors[,1] > 0
  yo_unobserved <- 1.5*x + errors[,2] > 0
  yo <- yo_unobserved * ys
  
  # sampleSelection package Heckman model
  
  heckit_coef <- coef(selection(as.factor(ys) ~ x, as.factor(yo) ~ x))[4]
  heckit_coefs[i] <- ifelse(!is.na(heckit_coef), heckit_coef, NA)

  # Self-made Sartori-estimator
  
  sartori_coef <- coef(maxLik(llf_sartori, start = c(1,2)))[2]
  sartori_coefs[i] <- ifelse(!is.na(sartori_coef), sartori_coef, NA)
  
  # Probit on outcome equation
  
  probit_coef <- coef(glm(yo ~ x, family = binomial(link = "probit")))[2]
  probit_coefs[i] <- ifelse(!is.na(probit_coef), probit_coef, NA)

}

```

